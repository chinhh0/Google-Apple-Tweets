{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports. nothing to see here.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from gensim.models import Word2Vec\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "source": [
    "# EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>emotion_in_tweet_is_directed_at</th>\n      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n      <td>iPhone</td>\n      <td>Negative emotion</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n      <td>iPad or iPhone App</td>\n      <td>Positive emotion</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n      <td>iPad</td>\n      <td>Positive emotion</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@sxsw I hope this year's festival isn't as cra...</td>\n      <td>iPad or iPhone App</td>\n      <td>Negative emotion</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n      <td>Google</td>\n      <td>Positive emotion</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Import and inspect data\n",
    "\n",
    "data = pd.read_csv('data.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Read content. These are a dataset of Tweets from SXSW in Austin from 2011.\n",
    "\n",
    "data.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the primary column and remove the one we find.\n",
    "\n",
    "print(data['tweet_text'].isna().sum())\n",
    "\n",
    "data = data[~data['tweet_text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# Number of duplicate rows dropped: 22\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated rows and preserve unique entries.\n",
    "\n",
    "a = len(data)\n",
    "data = data.drop_duplicates()\n",
    "b = len(data)\n",
    "print('# Number of duplicate rows dropped: {}'.format(a-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iPad                               945\nApple                              659\niPad or iPhone App                 469\nGoogle                             428\niPhone                             296\nOther Google product or service    293\nAndroid App                         80\nAndroid                             77\nOther Apple product or service      35\nName: emotion_in_tweet_is_directed_at, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore and simplify. We're defining our project goals more closely here.\n",
    "\n",
    "print(data['emotion_in_tweet_is_directed_at'].value_counts())\n",
    "\n",
    "company = {'iPad': 'Apple',\n",
    "            'Apple': 'Apple',\n",
    "            'iPad or iPhone App': 'Apple',\n",
    "            'Google': 'Google',\n",
    "            'iPhone': 'Apple',\n",
    "            'Other Google product or service': 'Google',\n",
    "            'Android App': 'Google',\n",
    "            'Android': 'Google',\n",
    "            'Other Apple product or service': 'Apple'}\n",
    "            \n",
    "data['emotion_in_tweet_is_directed_at'] = data['emotion_in_tweet_is_directed_at'].map(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify column names for convenience\n",
    "\n",
    "data.rename(columns={'tweet_text': 'text', 'emotion_in_tweet_is_directed_at': 'brand', 'is_there_an_emotion_directed_at_a_brand_or_product': 'feelings'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original dataset values:\n No emotion toward brand or product    5375\nPositive emotion                      2970\nNegative emotion                       569\nI can't tell                           156\nName: feelings, dtype: int64 \n\nEncoded and chosen dataset values:\n 1    2970\n0     569\nName: feelings, dtype: int64 \n\nTotal entries: 3539\n"
     ]
    }
   ],
   "source": [
    "# Here we inspect and encode the labels for our target column. We also define the boundaries of our task, narrowing our dataset to entries with clear positive or negative expressions.\n",
    "\n",
    "print('Original dataset values:\\n', data['feelings'].value_counts(), '\\n')\n",
    "\n",
    "feels = {'Negative emotion': 0,\n",
    "        'Positive emotion': 1,\n",
    "        'No emotion toward brand or product': 2,\n",
    "        \"I can't tell\": 3}\n",
    "\n",
    "data['feelings'] = data['feelings'].map(feels)\n",
    "\n",
    "data = data[data['feelings'] <= 1]\n",
    "\n",
    "print('Encoded and chosen dataset values:\\n', data['feelings'].value_counts(), '\\n')\n",
    "\n",
    "print('Total entries:', len(data))"
   ]
  },
  {
   "source": [
    "# Now the NLP begins."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tools to process the Tweets.\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "stops += list(string.punctuation)\n",
    "stops.extend(['sxsw', 'sxswi', 'quot', 'mention', 'link', 'rt', 'amp', 'http', 'sxswrt', 'google', 'googles', 'app', 'apps', 'android', 'austin', 'quotgoogle', 'new', 'today', 'one', 'apple', 'ipad', 'iphone', 'ipad2', 'apples', 'quotapple','store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text   brand  feelings  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   Apple         0   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   Apple         1   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   Apple         1   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   Apple         0   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...  Google         1   \n",
       "...                                                 ...     ...       ...   \n",
       "9077  @mention your PR guy just convinced me to swit...   Apple         1   \n",
       "9079  &quot;papyrus...sort of like the ipad&quot; - ...   Apple         1   \n",
       "9080  Diller says Google TV &quot;might be run over ...  Google         0   \n",
       "9085  I've always used Camera+ for my iPhone b/c it ...   Apple         1   \n",
       "9088                      Ipad everywhere. #SXSW {link}   Apple         1   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [wesley83, 3g, 3, hrs, tweeting, rise_austin, ...  \n",
       "1     [jessedee, know, fludapp, awesome, likely, app...  \n",
       "2                     [swonderlin, wait, 2, also, sale]  \n",
       "3                  [hope, year, festival, crashy, year]  \n",
       "4     [sxtxstate, great, stuff, fri, marissa, mayer,...  \n",
       "...                                                 ...  \n",
       "9077  [pr, guy, convinced, switch, back, great, cove...  \n",
       "9079          [papyrus, sort, like, nice, lol, lavelle]  \n",
       "9080  [diller, says, tv, might, run, playstation, xb...  \n",
       "9085  [always, used, camera, b, c, image, stabilizer...  \n",
       "9088                                       [everywhere]  \n",
       "\n",
       "[3539 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>brand</th>\n      <th>feelings</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n      <td>Apple</td>\n      <td>0</td>\n      <td>[wesley83, 3g, 3, hrs, tweeting, rise_austin, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[jessedee, know, fludapp, awesome, likely, app...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[swonderlin, wait, 2, also, sale]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@sxsw I hope this year's festival isn't as cra...</td>\n      <td>Apple</td>\n      <td>0</td>\n      <td>[hope, year, festival, crashy, year]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n      <td>Google</td>\n      <td>1</td>\n      <td>[sxtxstate, great, stuff, fri, marissa, mayer,...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9077</th>\n      <td>@mention your PR guy just convinced me to swit...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[pr, guy, convinced, switch, back, great, cove...</td>\n    </tr>\n    <tr>\n      <th>9079</th>\n      <td>&amp;quot;papyrus...sort of like the ipad&amp;quot; - ...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[papyrus, sort, like, nice, lol, lavelle]</td>\n    </tr>\n    <tr>\n      <th>9080</th>\n      <td>Diller says Google TV &amp;quot;might be run over ...</td>\n      <td>Google</td>\n      <td>0</td>\n      <td>[diller, says, tv, might, run, playstation, xb...</td>\n    </tr>\n    <tr>\n      <th>9085</th>\n      <td>I've always used Camera+ for my iPhone b/c it ...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[always, used, camera, b, c, image, stabilizer...</td>\n    </tr>\n    <tr>\n      <th>9088</th>\n      <td>Ipad everywhere. #SXSW {link}</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[everywhere]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3539 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Use our new tools!\n",
    "############### Tokens still in list form. Must be addressed #############\n",
    "\n",
    "data['tokens'] = data['text'].apply(tokenizer.tokenize)\n",
    "\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [word.lower() for word in x if word not in stops])\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [word.lower() for word in x if word not in stops])\n",
    "\n",
    "data"
   ]
  },
  {
   "source": [
    "# Creating functions for user interface"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "def lemmatize():\n",
    "    data['lemm'] = data['tokens'].apply(lemmatize_text)\n",
    "    data['lemm'] = data['lemm'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(X_train, X_test):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "    X_test_counts = count_vectorizer.transform(X_test)\n",
    "    return X_train_counts, X_test_counts\n",
    "\n",
    "def tf_idf(X_train, X_test):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_counts = tfidf.fit_transform(X_train)\n",
    "    X_test_counts = tfidf.transform(X_test)\n",
    "    return X_test_counts, X_train_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(X_train_counts, y_train):\n",
    "    smote = SMOTE()\n",
    "    X_train_counts, y_train = smote.fit_sample(X_train_counts, y_train)\n",
    "    return X_train_counts, y_train\n",
    "\n",
    "def TTS(col):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[col], data['feelings'])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg(X_train_counts, y_train, X_test_counts):\n",
    "    clf = LogisticRegression(C=30.0, class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', n_jobs=-1, random_state=40)\n",
    "    clf.fit(X_train_counts, y_train)\n",
    "    y_predicted_counts = clf.predict(X_test_counts)\n",
    "    return y_predicted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(X_train_counts, y_train, X_test_counts):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train_counts, y_train)\n",
    "    y_predicted_counts = rf.predict(X_test_counts)\n",
    "    return y_predicted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiNB(X_train_counts, y_train, X_test_counts):\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_counts, y_train)\n",
    "    y_predicted_counts = nb.predict(X_test_counts)\n",
    "    return y_predicted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(y_test, y_predicted_counts):\n",
    "    print('\\n\\nClassification Report - TEST')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(classification_report(y_test, y_predicted_counts))\n",
    "    # Confusion Matrix\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('Confusion Matrix - TEST')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(pd.crosstab(y_test, y_predicted_counts, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print('--------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_models(data):\n",
    "    col = None\n",
    "    model = None\n",
    "    lemm = None\n",
    "    smt = None\n",
    "    reco = None\n",
    "    picks = []\n",
    "    choices = [logreg, rf, multiNB]\n",
    "    t = None\n",
    "\n",
    "    log = [[1, 2, 2], [2,2,2]]\n",
    "    forest = [[1,1,2],[2,1,2],[2,1,1]]\n",
    "    NB = [[1,2,1],[2,2,1],[1,1,1,]]\n",
    "\n",
    "    # LR = 1, RF = 2, MNB = 3\n",
    "    jerk = \"Don't waste my time. Try again wiseguy.\"\n",
    "\n",
    "    print('How would you like to analyze the data?\\nType \"1\" to Count Vectorize or \"2\" to implement TF-IDF.\\n')\n",
    "    model = input()\n",
    "    picks.append(int(model))\n",
    "    if model not in ['1', '2']:\n",
    "        return print(jerk)\n",
    "\n",
    "    print('Would you like to lemmatize?\\nType \"1\" for Yes or \"2\" for No.\\n')\n",
    "    lemm  = input()\n",
    "    picks.append(int(lemm))\n",
    "    if lemm not in ['1', '2']:\n",
    "        return print(jerk)\n",
    "\n",
    "    print('Would you like to SMOTE?\\nType \"1\" for Yes or \"2\" for No.\\n')\n",
    "    smt = input()\n",
    "    picks.append(int(smt))\n",
    "    if smt not in ['1','2']:\n",
    "        return print(jerk)\n",
    "\n",
    "    if lemm == '1':\n",
    "        col = 'lemm'\n",
    "        lemmatize()\n",
    "        print('Lemmatized changed this many rows:', (len(data) - (sum(data['tokens'] == data['lemm']))),'\\n')\n",
    "    elif lemm == '2':\n",
    "        col = 'tokens'\n",
    "        data['tokens'] = data['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    if picks in log:\n",
    "        t = 0\n",
    "    elif picks in forest:\n",
    "        t = 1\n",
    "    elif picks in NB:\n",
    "        t = 2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = TTS(col)\n",
    "\n",
    "    if model == '1':\n",
    "        X_train_counts, X_test_counts = CV(X_train, X_test)\n",
    "        data ['tokens'] = data['tokens'].apply(lambda x: ' '.join(x))\n",
    "    elif model == '2':\n",
    "        X_test_counts, X_train_counts = tf_idf(X_train, X_test)\n",
    "\n",
    "    if smt == '1':\n",
    "        X_train_counts, y_train = smote(X_train_counts, y_train)\n",
    " \n",
    "    print('Would you like to pick your model or use our recomendation?\\nType \"1\" to choose or \"2\" to let us.')\n",
    "    reco = input()\n",
    "    if reco not in ['1','2']:\n",
    "        return print(jerk)\n",
    "    elif reco == '1':\n",
    "        print('\\n\\n\"1\" for Logistic Regression\\n\"2\" for Random Forest\\n\"3\" for Multinomial Naive Bayes')\n",
    "        t = (int(input()) - 1)\n",
    "\n",
    "\n",
    "\n",
    "    mod = choices[t]\n",
    "    if mod == logreg:\n",
    "        print('\\n\\nLogistic Regression Report')\n",
    "    elif mod == rf:\n",
    "        print('\\n\\nRandom Forest Report')\n",
    "    elif mod == multiNB:\n",
    "        print('\\n\\nMultinomial Naive Bayes')\n",
    "\n",
    "    y_predicted_counts = mod(X_train_counts, y_train, X_test_counts)\n",
    "    classify(y_test, y_predicted_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "How would you like to analyze the data?\n",
      "Type \"1\" to Count Vectorize or \"2\" to implement TF-IDF.\n",
      "\n",
      "Would you like to lemmatize?\n",
      "Type \"1\" for Yes or \"2\" for No.\n",
      "\n",
      "Would you like to SMOTE?\n",
      "Type \"1\" for Yes or \"2\" for No.\n",
      "\n",
      "Lemmatized changed this many rows: 3539 \n",
      "\n",
      "Would you like to pick your model or use our recomendation?\n",
      "Type \"1\" to choose or \"2\" to let us.\n",
      "\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "\n",
      "\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.49      0.47       143\n",
      "           1       0.90      0.89      0.89       742\n",
      "\n",
      "    accuracy                           0.82       885\n",
      "   macro avg       0.68      0.69      0.68       885\n",
      "weighted avg       0.83      0.82      0.82       885\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted    0    1  All\n",
      "True                    \n",
      "0           70   73  143\n",
      "1           85  657  742\n",
      "All        155  730  885\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_models(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text   brand  feelings  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   Apple         0   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   Apple         1   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   Apple         1   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   Apple         0   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...  Google         1   \n",
       "...                                                 ...     ...       ...   \n",
       "9077  @mention your PR guy just convinced me to swit...   Apple         1   \n",
       "9079  &quot;papyrus...sort of like the ipad&quot; - ...   Apple         1   \n",
       "9080  Diller says Google TV &quot;might be run over ...  Google         0   \n",
       "9085  I've always used Camera+ for my iPhone b/c it ...   Apple         1   \n",
       "9088                      Ipad everywhere. #SXSW {link}   Apple         1   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     wesley83 3g 3 hrs tweeting rise_austin dead ne...   \n",
       "1     jessedee know fludapp awesome likely appreciat...   \n",
       "2                           swonderlin wait 2 also sale   \n",
       "3                        hope year festival crashy year   \n",
       "4     sxtxstate great stuff fri marissa mayer tim re...   \n",
       "...                                                 ...   \n",
       "9077  pr guy convinced switch back great coverage pr...   \n",
       "9079                 papyrus sort like nice lol lavelle   \n",
       "9080  diller says tv might run playstation xbox esse...   \n",
       "9085  always used camera b c image stabilizer mode s...   \n",
       "9088                                         everywhere   \n",
       "\n",
       "                                                   lemm  \n",
       "0     wesley83 3g 3 hr tweeting rise_austin dead nee...  \n",
       "1     jessedee know fludapp awesome likely appreciat...  \n",
       "2                           swonderlin wait 2 also sale  \n",
       "3                        hope year festival crashy year  \n",
       "4     sxtxstate great stuff fri marissa mayer tim re...  \n",
       "...                                                 ...  \n",
       "9077  pr guy convinced switch back great coverage pr...  \n",
       "9079                 papyrus sort like nice lol lavelle  \n",
       "9080  diller say tv might run playstation xbox essen...  \n",
       "9085  always used camera b c image stabilizer mode s...  \n",
       "9088                                         everywhere  \n",
       "\n",
       "[3539 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>brand</th>\n      <th>feelings</th>\n      <th>tokens</th>\n      <th>lemm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n      <td>Apple</td>\n      <td>0</td>\n      <td>wesley83 3g 3 hrs tweeting rise_austin dead ne...</td>\n      <td>wesley83 3g 3 hr tweeting rise_austin dead nee...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>jessedee know fludapp awesome likely appreciat...</td>\n      <td>jessedee know fludapp awesome likely appreciat...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>swonderlin wait 2 also sale</td>\n      <td>swonderlin wait 2 also sale</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@sxsw I hope this year's festival isn't as cra...</td>\n      <td>Apple</td>\n      <td>0</td>\n      <td>hope year festival crashy year</td>\n      <td>hope year festival crashy year</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n      <td>Google</td>\n      <td>1</td>\n      <td>sxtxstate great stuff fri marissa mayer tim re...</td>\n      <td>sxtxstate great stuff fri marissa mayer tim re...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9077</th>\n      <td>@mention your PR guy just convinced me to swit...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>pr guy convinced switch back great coverage pr...</td>\n      <td>pr guy convinced switch back great coverage pr...</td>\n    </tr>\n    <tr>\n      <th>9079</th>\n      <td>&amp;quot;papyrus...sort of like the ipad&amp;quot; - ...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>papyrus sort like nice lol lavelle</td>\n      <td>papyrus sort like nice lol lavelle</td>\n    </tr>\n    <tr>\n      <th>9080</th>\n      <td>Diller says Google TV &amp;quot;might be run over ...</td>\n      <td>Google</td>\n      <td>0</td>\n      <td>diller says tv might run playstation xbox esse...</td>\n      <td>diller say tv might run playstation xbox essen...</td>\n    </tr>\n    <tr>\n      <th>9085</th>\n      <td>I've always used Camera+ for my iPhone b/c it ...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>always used camera b c image stabilizer mode s...</td>\n      <td>always used camera b c image stabilizer mode s...</td>\n    </tr>\n    <tr>\n      <th>9088</th>\n      <td>Ipad everywhere. #SXSW {link}</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>everywhere</td>\n      <td>everywhere</td>\n    </tr>\n  </tbody>\n</table>\n<p>3539 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}