{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports. nothing to see here.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from gensim.models import Word2Vec\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "source": [
    "# EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>emotion_in_tweet_is_directed_at</th>\n      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n      <td>iPhone</td>\n      <td>Negative emotion</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n      <td>iPad or iPhone App</td>\n      <td>Positive emotion</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n      <td>iPad</td>\n      <td>Positive emotion</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@sxsw I hope this year's festival isn't as cra...</td>\n      <td>iPad or iPhone App</td>\n      <td>Negative emotion</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n      <td>Google</td>\n      <td>Positive emotion</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Import and inspect data\n",
    "\n",
    "data = pd.read_csv('data.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Read content. These are a dataset of Tweets from SXSW in Austin from 2011.\n",
    "\n",
    "data.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the primary column and remove the one we find.\n",
    "\n",
    "print(data['tweet_text'].isna().sum())\n",
    "\n",
    "data = data[~data['tweet_text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# Number of duplicate rows dropped: 22\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated rows and preserve unique entries.\n",
    "\n",
    "a = len(data)\n",
    "data = data.drop_duplicates()\n",
    "b = len(data)\n",
    "print('# Number of duplicate rows dropped: {}'.format(a-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iPad                               945\nApple                              659\niPad or iPhone App                 469\nGoogle                             428\niPhone                             296\nOther Google product or service    293\nAndroid App                         80\nAndroid                             77\nOther Apple product or service      35\nName: emotion_in_tweet_is_directed_at, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore and simplify. We're defining our project goals more closely here.\n",
    "\n",
    "print(data['emotion_in_tweet_is_directed_at'].value_counts())\n",
    "\n",
    "company = {'iPad': 'Apple',\n",
    "            'Apple': 'Apple',\n",
    "            'iPad or iPhone App': 'Apple',\n",
    "            'Google': 'Google',\n",
    "            'iPhone': 'Apple',\n",
    "            'Other Google product or service': 'Google',\n",
    "            'Android App': 'Google',\n",
    "            'Android': 'Google',\n",
    "            'Other Apple product or service': 'Apple'}\n",
    "            \n",
    "data['emotion_in_tweet_is_directed_at'] = data['emotion_in_tweet_is_directed_at'].map(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify column names for convenience\n",
    "\n",
    "data.rename(columns={'tweet_text': 'text', 'emotion_in_tweet_is_directed_at': 'brand', 'is_there_an_emotion_directed_at_a_brand_or_product': 'feelings'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original dataset values:\n No emotion toward brand or product    5375\nPositive emotion                      2970\nNegative emotion                       569\nI can't tell                           156\nName: feelings, dtype: int64 \n\nEncoded and chosen dataset values:\n 1    2970\n0     569\nName: feelings, dtype: int64 \n\nTotal entries: 3539\n"
     ]
    }
   ],
   "source": [
    "# Here we inspect and encode the labels for our target column. We also define the boundaries of our task, narrowing our dataset to entries with clear positive or negative expressions.\n",
    "\n",
    "print('Original dataset values:\\n', data['feelings'].value_counts(), '\\n')\n",
    "\n",
    "feels = {'Negative emotion': 0,\n",
    "        'Positive emotion': 1,\n",
    "        'No emotion toward brand or product': 2,\n",
    "        \"I can't tell\": 3}\n",
    "\n",
    "data['feelings'] = data['feelings'].map(feels)\n",
    "\n",
    "data = data[data['feelings'] <= 1]\n",
    "\n",
    "print('Encoded and chosen dataset values:\\n', data['feelings'].value_counts(), '\\n')\n",
    "\n",
    "print('Total entries:', len(data))"
   ]
  },
  {
   "source": [
    "# Now the NLP begins."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tools to process the Tweets.\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "stops += list(string.punctuation)\n",
    "stops.extend(['sxsw', 'sxswi', 'quot', 'mention', 'link', 'rt', 'amp', 'http', 'sxswrt', 'google', 'googles', 'app', 'apps', 'android', 'austin', 'quotgoogle', 'new', 'today', 'one', 'apple', 'ipad', 'iphone', 'ipad2', 'apples', 'quotapple','store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text   brand  feelings  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   Apple         0   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   Apple         1   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   Apple         1   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   Apple         0   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...  Google         1   \n",
       "...                                                 ...     ...       ...   \n",
       "9077  @mention your PR guy just convinced me to swit...   Apple         1   \n",
       "9079  &quot;papyrus...sort of like the ipad&quot; - ...   Apple         1   \n",
       "9080  Diller says Google TV &quot;might be run over ...  Google         0   \n",
       "9085  I've always used Camera+ for my iPhone b/c it ...   Apple         1   \n",
       "9088                      Ipad everywhere. #SXSW {link}   Apple         1   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [wesley83, 3g, 3, hrs, tweeting, rise_austin, ...  \n",
       "1     [jessedee, know, fludapp, awesome, likely, app...  \n",
       "2                     [swonderlin, wait, 2, also, sale]  \n",
       "3                  [hope, year, festival, crashy, year]  \n",
       "4     [sxtxstate, great, stuff, fri, marissa, mayer,...  \n",
       "...                                                 ...  \n",
       "9077  [pr, guy, convinced, switch, back, great, cove...  \n",
       "9079          [papyrus, sort, like, nice, lol, lavelle]  \n",
       "9080  [diller, says, tv, might, run, playstation, xb...  \n",
       "9085  [always, used, camera, b, c, image, stabilizer...  \n",
       "9088                                       [everywhere]  \n",
       "\n",
       "[3539 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>brand</th>\n      <th>feelings</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n      <td>Apple</td>\n      <td>0</td>\n      <td>[wesley83, 3g, 3, hrs, tweeting, rise_austin, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[jessedee, know, fludapp, awesome, likely, app...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[swonderlin, wait, 2, also, sale]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@sxsw I hope this year's festival isn't as cra...</td>\n      <td>Apple</td>\n      <td>0</td>\n      <td>[hope, year, festival, crashy, year]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n      <td>Google</td>\n      <td>1</td>\n      <td>[sxtxstate, great, stuff, fri, marissa, mayer,...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9077</th>\n      <td>@mention your PR guy just convinced me to swit...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[pr, guy, convinced, switch, back, great, cove...</td>\n    </tr>\n    <tr>\n      <th>9079</th>\n      <td>&amp;quot;papyrus...sort of like the ipad&amp;quot; - ...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[papyrus, sort, like, nice, lol, lavelle]</td>\n    </tr>\n    <tr>\n      <th>9080</th>\n      <td>Diller says Google TV &amp;quot;might be run over ...</td>\n      <td>Google</td>\n      <td>0</td>\n      <td>[diller, says, tv, might, run, playstation, xb...</td>\n    </tr>\n    <tr>\n      <th>9085</th>\n      <td>I've always used Camera+ for my iPhone b/c it ...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[always, used, camera, b, c, image, stabilizer...</td>\n    </tr>\n    <tr>\n      <th>9088</th>\n      <td>Ipad everywhere. #SXSW {link}</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[everywhere]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3539 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Use our new tools!\n",
    "############### Tokens still in list form. Must be addressed #############\n",
    "\n",
    "data['tokens'] = data['text'].apply(tokenizer.tokenize)\n",
    "\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [word.lower() for word in x if word not in stops])\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [word.lower() for word in x if word not in stops])\n",
    "\n",
    "data"
   ]
  },
  {
   "source": [
    "# Creating functions for user interface"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "def lemmatize():\n",
    "    data['lemm'] = data['tokens'].apply(lemmatize_text)\n",
    "    data['lemm'] = data['lemm'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(X_train, X_test):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "    X_test_counts = count_vectorizer.transform(X_test)\n",
    "    return X_train_counts, X_test_counts\n",
    "\n",
    "def tf_idf(X_train, X_test):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_counts = tfidf.fit_transform(X_train)\n",
    "    X_test_counts = tfidf.transform(X_test)\n",
    "    return X_test_counts, X_train_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(X_train_counts, y_train):\n",
    "    smote = SMOTE()\n",
    "    X_train_counts, y_train = smote.fit_sample(X_train_counts, y_train)\n",
    "    return X_train_counts, y_train\n",
    "\n",
    "def TTS(col):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[col], data['feelings'])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg(X_train_counts, y_train, X_test_counts):\n",
    "    clf = LogisticRegression(C=30.0, class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', n_jobs=-1, random_state=40)\n",
    "    clf.fit(X_train_counts, y_train)\n",
    "    y_predicted_counts = clf.predict(X_test_counts)\n",
    "    return y_predicted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(X_train_counts, y_train, X_test_counts):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train_counts, y_train)\n",
    "    y_predicted_counts = rf.predict(X_test_counts)\n",
    "    return y_predicted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiNB(X_train_counts, y_train, X_test_counts):\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_counts, y_train)\n",
    "    y_predicted_counts = nb.predict(X_test_counts)\n",
    "    return y_predicted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(y_test, y_predicted_counts):\n",
    "    print('Classification Report - TEST')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(classification_report(y_test, y_predicted_counts))\n",
    "    # Confusion Matrix\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('Confusion Matrix - TEST')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(pd.crosstab(y_test, y_predicted_counts, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print('--------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_models(data):\n",
    "    col = None\n",
    "    model = None\n",
    "    lemm = None\n",
    "    smt = None\n",
    "    jerk = \"Don't waste my time. Try again wiseguy.\"\n",
    "\n",
    "    print('How would you like to analyze the data?\\nType \"1\" to Count Vectorize or \"2\" to implement TF-IDF.')\n",
    "    model = input()\n",
    "    if model not in ['1', '2']:\n",
    "        return print(jerk)\n",
    "\n",
    "    print('Would you like to lemmatize?\\nType \"1\" for Yes or \"2\" for No.')\n",
    "    lemm  = input()\n",
    "    if lemm not in ['1', '2']:\n",
    "        return print(jerk)\n",
    "\n",
    "    print('Would you like to SMOTE?\\nType \"1\" for Yes or \"2\" for No.')\n",
    "    smt = input()\n",
    "    if smt not in ['1','2']:\n",
    "        return print(jerk)\n",
    "\n",
    "    if lemm == '1':\n",
    "        col = 'lemm'\n",
    "        lemmatize()\n",
    "    elif lemm == '2':\n",
    "        col = 'text'\n",
    "\n",
    "    X_train, X_test, y_train, y_test = TTS(col)\n",
    "    # print(X_train)\n",
    "\n",
    "    if model == '1':\n",
    "        X_train_counts, y_test_counts = CV(X_train, X_test)\n",
    "        data ['tokens'] = data['tokens'].apply(lambda x: ' '.join(x))\n",
    "    elif model == '2':\n",
    "        X_test_counts, X_train_counts = tf_idf(X_train, X_test)\n",
    "\n",
    "    if smt == '1':\n",
    "        X_train_counts, y_train = smote(X_train_counts, y_train)\n",
    "\n",
    "    y_predicted_counts = multiNB(X_train_counts, y_train, X_test_counts)\n",
    "    classify(y_test, y_predicted_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "How would you like to analyze the data?\n",
      "Type \"1\" to Count Vectorize or \"2\" to implement TF-IDF.\n",
      "Would you like to lemmatize?\n",
      "Type \"1\" for Yes or \"2\" for No.\n",
      "Would you like to SMOTE?\n",
      "Type \"1\" for Yes or \"2\" for No.\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06       137\n",
      "           1       0.85      1.00      0.92       748\n",
      "\n",
      "    accuracy                           0.85       885\n",
      "   macro avg       0.92      0.51      0.49       885\n",
      "weighted avg       0.87      0.85      0.78       885\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted  0    1  All\n",
      "True                  \n",
      "0          4  133  137\n",
      "1          0  748  748\n",
      "All        4  881  885\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_models(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text   brand  feelings  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   Apple         0   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   Apple         1   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   Apple         1   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   Apple         0   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...  Google         1   \n",
       "...                                                 ...     ...       ...   \n",
       "9077  @mention your PR guy just convinced me to swit...   Apple         1   \n",
       "9079  &quot;papyrus...sort of like the ipad&quot; - ...   Apple         1   \n",
       "9080  Diller says Google TV &quot;might be run over ...  Google         0   \n",
       "9085  I've always used Camera+ for my iPhone b/c it ...   Apple         1   \n",
       "9088                      Ipad everywhere. #SXSW {link}   Apple         1   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [wesley83, 3g, 3, hrs, tweeting, rise_austin, ...  \n",
       "1     [jessedee, know, fludapp, awesome, likely, app...  \n",
       "2                     [swonderlin, wait, 2, also, sale]  \n",
       "3                  [hope, year, festival, crashy, year]  \n",
       "4     [sxtxstate, great, stuff, fri, marissa, mayer,...  \n",
       "...                                                 ...  \n",
       "9077  [pr, guy, convinced, switch, back, great, cove...  \n",
       "9079          [papyrus, sort, like, nice, lol, lavelle]  \n",
       "9080  [diller, says, tv, might, run, playstation, xb...  \n",
       "9085  [always, used, camera, b, c, image, stabilizer...  \n",
       "9088                                       [everywhere]  \n",
       "\n",
       "[3539 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>brand</th>\n      <th>feelings</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n      <td>Apple</td>\n      <td>0</td>\n      <td>[wesley83, 3g, 3, hrs, tweeting, rise_austin, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[jessedee, know, fludapp, awesome, likely, app...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[swonderlin, wait, 2, also, sale]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@sxsw I hope this year's festival isn't as cra...</td>\n      <td>Apple</td>\n      <td>0</td>\n      <td>[hope, year, festival, crashy, year]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n      <td>Google</td>\n      <td>1</td>\n      <td>[sxtxstate, great, stuff, fri, marissa, mayer,...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9077</th>\n      <td>@mention your PR guy just convinced me to swit...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[pr, guy, convinced, switch, back, great, cove...</td>\n    </tr>\n    <tr>\n      <th>9079</th>\n      <td>&amp;quot;papyrus...sort of like the ipad&amp;quot; - ...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[papyrus, sort, like, nice, lol, lavelle]</td>\n    </tr>\n    <tr>\n      <th>9080</th>\n      <td>Diller says Google TV &amp;quot;might be run over ...</td>\n      <td>Google</td>\n      <td>0</td>\n      <td>[diller, says, tv, might, run, playstation, xb...</td>\n    </tr>\n    <tr>\n      <th>9085</th>\n      <td>I've always used Camera+ for my iPhone b/c it ...</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[always, used, camera, b, c, image, stabilizer...</td>\n    </tr>\n    <tr>\n      <th>9088</th>\n      <td>Ipad everywhere. #SXSW {link}</td>\n      <td>Apple</td>\n      <td>1</td>\n      <td>[everywhere]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3539 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-931765772341>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}